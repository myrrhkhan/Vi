{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Script\n",
    "Contains function that takes image and makes prediction from model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myrrh/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import StringLookup\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dotkeras_path: str):\n",
    "    prediction_model = tf.keras.models.load_model(dotkeras_path)\n",
    "    return prediction_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 21:52:22.444871: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-01-13 21:52:22.444894: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 24.00 GB\n",
      "2024-01-13 21:52:22.444901: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 8.00 GB\n",
      "2024-01-13 21:52:22.444940: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-13 21:52:22.444962: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "batch_size = 1\n",
    "padding_token = 99\n",
    "image_width = 128\n",
    "image_height = 32\n",
    "max_len = 21\n",
    "\n",
    "charfile = open('./models/characters.txt', 'r')\n",
    "characters = charfile.read()\n",
    "characters = characters.split(' ')\n",
    "\n",
    "# Mapping characters to integers.\n",
    "char_to_num = StringLookup(vocabulary=list(characters), mask_token=None)\n",
    "\n",
    "# Mapping integers back to original characters.\n",
    "num_to_char = StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")\n",
    "\n",
    "def distortion_free_resize(image, img_size):\n",
    "    w, h = img_size\n",
    "    image = tf.image.resize_with_pad(image, h, w)\n",
    "    # documentation had a different thing with \n",
    "    # tf.image.resize, find padding diff, then tf.pad\n",
    "    # found this function instead and I guess it works fine\n",
    "\n",
    "    # lines below convert from vertical to horizontal, then flips to correct orientation\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    return image\n",
    "\n",
    "def preprocess_image(image_path, img_size=(image_width, image_height)):\n",
    "    # plot image as test\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, 1) # 1: output to grayscale. tensor of uint8 or uint16\n",
    "    image = distortion_free_resize(image, img_size)\n",
    "    image = tf.cast(image, tf.float32) / 255.0 # cast to float instead of int\n",
    "    return image\n",
    "\n",
    "def process_image_labels(image_path, label):\n",
    "    # calls above functions, gets preprocessed image and label, returns as dict\n",
    "    image = preprocess_image(image_path)\n",
    "    return {\"image\": image, \"label\": label}\n",
    "\n",
    "def prepare_dataset(image_paths, labels):\n",
    "    # calls all functions above, makes tf dataset with image paths, \n",
    "    # maps image paths and labels to tf images and tf labels\n",
    "    # TODO look up AUTOTUNE\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(\n",
    "        process_image_labels, num_parallel_calls=AUTOTUNE\n",
    "    )\n",
    "    return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image prediction function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to decode the output of the network.\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search.\n",
    "    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
    "        :, :max_len\n",
    "    ]\n",
    "    # Iterate over the results and get back the text.\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path: str, dotkeras_path: str) -> str:\n",
    "    dataset = prepare_dataset([img_path], [\"null\"])\n",
    "    prediction_model = load_model(dotkeras_path)\n",
    "    for batch in dataset:\n",
    "        batch_image = batch[\"image\"]\n",
    "        pred = prediction_model.predict(batch_image)\n",
    "        pred_text = decode_batch_predictions(pred)\n",
    "\n",
    "    return pred_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 596ms/step\n",
      "1/1 [==============================] - 1s 575ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('./data/words/a01/a01-000u/a01-000u-00-00.png', './models/50_epochs.keras')\n",
    "predict('./data/words/a02/a02-000/a02-000-00-04.png', './models/50_epochs.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
